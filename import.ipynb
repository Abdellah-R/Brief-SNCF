{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des données objets perdus (Lost Item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specific_url_lostitem(annee,mois):\n",
    "    URL = \"https://ressources.data.sncf.com/api/records/1.0/search/\"\n",
    "    ressource = \"?dataset=objets-trouves-restitution&q=&rows=10000&sort=date&facet=date&facet=gc_obo_date_heure_restitution_c&facet=gc_obo_gare_origine_r_name&facet=gc_obo_nature_c&facet=gc_obo_type_c&facet=gc_obo_nom_recordtype_sc_c&refine.date=\"\n",
    "    month_format = f\"{annee}%2F{mois}\"\n",
    "    return URL + ressource + month_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_model import LostItem\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# on crée un moteur de base de données (objet qui gère la connexion à la base de données et permet d'exécuter des requêtes SQL sur cette base de données.)\n",
    "engine = create_engine('sqlite:///db.sqlite')\n",
    "\n",
    "# on crée un \"fabricant de session\" pour créer une session de base de données qui gère l'ajout et la modification d'objets dans la BDD.)\n",
    "Session = sessionmaker(bind=engine)\n",
    "\n",
    "# on instancie une session de base de données\n",
    "session = Session()\n",
    "\n",
    "liste_mois = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]\n",
    "liste_annee = [\"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\"]\n",
    "\n",
    "# dictionnaire qui permet d'associer un nom de variable à une clé dans la boucle \"for cle in dico.items()\"\n",
    "dico = {'date': 'date_var', 'gc_obo_type_c': 'type_var', 'gc_obo_gare_origine_r_name': 'gare_var', 'gc_obo_gare_origine_r_code_uic_c': 'code_uic_var', \n",
    "'gc_obo_date_heure_restitution_c': 'date_rest_var'}\n",
    "\n",
    "for annee  in liste_annee:\n",
    "    for mois in liste_mois:\n",
    "        url = specific_url_lostitem(annee,mois)\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        for itemlost in response.json()[\"records\"]:\n",
    "\n",
    "            # on teste à chaque fois s'il existe une valeur que l'on peut enregistrer dans la base de données, sinon affecte la valeur None pour indiquer dans la BDD l'absence d'informations':\n",
    "            for cle in dico.keys():\n",
    "                try:\n",
    "                    dico[cle] = itemlost['fields'][cle]\n",
    "                except KeyError:\n",
    "                    dico[cle] = None\n",
    "\n",
    "            # on ajoute une nouvelle ligne dans la base de données avec les informations contenues dans le json\n",
    "            session.add(LostItem(id = itemlost['recordid'],\n",
    "                                date = dico['date'],\n",
    "                                type_objet = dico['gc_obo_type_c'],\n",
    "                                gare = dico['gc_obo_gare_origine_r_name'],\n",
    "                                code_uic = dico['gc_obo_gare_origine_r_code_uic_c'],\n",
    "                                date_restitution = dico['gc_obo_date_heure_restitution_c']))\n",
    "\n",
    "# on  valide tous les changements apportés aux objets de la session et on les enregistre dans la base de données.\n",
    "session.commit() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des données sur les gares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_model import Gare\n",
    "\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "url = \"https://ressources.data.sncf.com/api/records/1.0/search/?dataset=referentiel-gares-voyageurs&q=&rows=10000\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "# liste dans laquelle on a regroupé par paire le nom d'une colonne de la table Gare avec le libellé correspondant dans le json\n",
    "field_list = [\n",
    "    [\"code_uic\", \"uic_code\"],\n",
    "    [\"nom_gare\", \"gare_alias_libelle_noncontraint\"],\n",
    "    [\"code_commune\", \"commune_code\"],\n",
    "    [\"code_postal\", \"adresse_cp\"],\n",
    "    [\"code_departement\", \"departement_numero\"],\n",
    "    [\"departement\", \"departement_libellemin\"],\n",
    "    [\"longitude\", \"longitude_entreeprincipale_wgs84\"],\n",
    "    [\"latitude\", \"latitude_entreeprincipale_wgs84\"]\n",
    "]\n",
    "\n",
    "# pour chaque gare dans le fichier json\n",
    "for gare in response.json()[\"records\"]:\n",
    "    \n",
    "    # on initialise un dictionnaire qui contiendra les données que l'on veut récupérer concernant la gare\n",
    "    gare_data= {}\n",
    "\n",
    "    # on récupère l'id \n",
    "    gare_data[\"id\"] = gare[\"recordid\"]\n",
    "\n",
    "    # pour chaque colonne\n",
    "    for field in field_list:\n",
    "\n",
    "        # on vérifie si la donnée existe pour la stocker dans la BDD, sinon on affecte la valeur none \n",
    "        try: \n",
    "            gare_data[field[0]] = gare[\"fields\"][field[1]]\n",
    "        except KeyError:\n",
    "            gare_data[field[0]]=None\n",
    "\n",
    "    # la syntaxe ** est utlisé  pour passer les valeurs du dico gare_data au constructeur de la classe Gare sans devoir réécrire les attributs de Gare\n",
    "    session.add(Gare(**gare_data))\n",
    "    session.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des données sur la fréquentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_model import Frequentation\n",
    "\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "url = \"https://ressources.data.sncf.com/api/records/1.0/search/?dataset=frequentation-gares&q=&sort=nom_gare&rows=10000\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# liste dans laquelle on a regroupé par paire le nom d'une colonne de la table Frequentation avec le libellé correspondant dans le json\n",
    "field_list = [\n",
    "    [\"code_uic\", \"code_uic_complet\"],\n",
    "    [\"code_postal\", \"code_postal\"],\n",
    "    [\"total_voyageurs_2016\", \"total_voyageurs_2016\"],\n",
    "    [\"total_voyageurs_2017\", \"totalvoyageurs2017\"],\n",
    "    [\"total_voyageurs_2018\", \"total_voyageurs_2018\"],\n",
    "    [\"total_voyageurs_2019\", \"total_voyageurs_2019\"],\n",
    "    [\"total_voyageurs_2020\", \"total_voyageurs_2020\"],\n",
    "    [\"total_voyageurs_2021\", \"total_voyageurs_2021\"]\n",
    "]\n",
    "\n",
    "for frequentation in response.json()[\"records\"]:\n",
    "\n",
    "    frequentation_data= {}\n",
    "    frequentation_data[\"id\"] = frequentation[\"recordid\"]\n",
    "\n",
    "    for field in field_list:\n",
    "        try: \n",
    "            frequentation_data[field[0]] = frequentation[\"fields\"][field[1]]\n",
    "        except KeyError:\n",
    "            frequentation_data[field[0]]=None\n",
    "\n",
    "   \n",
    "    session.add(Frequentation(**frequentation_data))\n",
    "    session.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des données sur la température"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_model import Temperature\n",
    "import csv\n",
    "\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# ouvre le fichier CSV nommé \"agregated_temperature.csv\" en mode lecture (\"r\")\n",
    "with open('agregated_temperature.csv', 'r') as csv_file:\n",
    "\n",
    "    # l'objet csv.DictReader est un lecteur de fichiers CSV qui permet de lire chaque ligne du fichier CSV en tant que dictionnaire, avec les en-têtes de colonne comme clés et les valeurs de chaque colonne comme valeurs.\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    \n",
    "    for row in csv_reader:\n",
    "        temperature = Temperature(departement_code = row['departement_code'],\n",
    "                                  date = row['Date'],\n",
    "                                  temperature = row['temperature'])\n",
    "        session.add(temperature)\n",
    "\n",
    "session.commit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b50150482caf52b8e28069b19d1fffaf1700a98d30aea6d889e3213a87e809c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
